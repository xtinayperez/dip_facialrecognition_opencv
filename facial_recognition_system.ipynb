# install libraries
# !pip install dlib
# !pip install face_recognition
# !pip install opencv-python

# importing libraies
import os
import cv2
import face_recognition
import pickles
import numpy as np
from google.colab import drive, files
from google.colab.patches import cv2_imshow

# defining the path for training images
drive.mount('/drive', force_remount = True)
drive_path = '/drive/MyDrive/dataset/train_images
drive_path = '/content'
os.chdir(local_path)

# reading and storing the training images into corresponding list
img = []
cNames = []
myList = os.listdir(drive_path)
for cl in mylist:
  curImg = cv2.imread(f'{drive_path}/{cl}')
  img.append(curImg)
  cNames.append(os.path.splitext(cl)[0]

# finding the encoded data of the input image
def findEncodings(img)
  encodeList = []
  for imgs in img:
    imgs = cv2.cvtColor(imgs, cv2.COLOR_BRG2RGB)
    encoded_face = face_recognition.face_encodings((img)[0]
    encodeList.append(encoded_face)
  return encodeList
# finding the encodings of training images
knownEnc = findEncodings(img)

# detecting and encoding faces from the user-uploaded image
upload = files.upload()
for fn in upload.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name = fn, length = len(upload[fn])))
  
img_test = cv2.imread(fn)
img_test_w = cv2.resize(img_test, (0, 0), None, 0.25, 0.25)
img_test_w = cv2.cvtColor(img_test_w, cv2.COLOR_BGR2RGB)
frame_face = face_recognition.face_locations(img_test_w)
enc_faces = face_recognition.face_encodings(img_test_w, frame_face)

# finding the matches between the detected faces and 
# the training images faces
for enc_face, faceloc in zip(enc_faces, frame_face):
  matches = face_recognition.compare_faces(knownEnc, enc_face, tolerance = 0.6)
  faceDist = face_recognition.face_distance(knownEnc, enc_face)
  matchIndex = np.argmin(faceDist)
  if matches[matchIndex]:
    name = cNames[matchIndex].upper().lower()
  
    y1, x2, y2, x1 = faceloc
    y1, x2, y2, x1 = y1*4, x2*4, y2*4, x1*4
    cv2.rectangle(img_test, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.rectangle(img_test, (x1, y2-35), (x2, y2), (0, 255, 0), cv2.FILLED)
    cv2.putText(img_test, name, (x1+6, y2-5), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)
    cv2_imshow(img_test)

  if cv2.waitKey(1) & 0xFF == ord('q'):
    break
